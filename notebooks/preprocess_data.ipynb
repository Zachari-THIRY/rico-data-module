{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not '..' in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the univariate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rico_data_module import RICODataset, DatasetParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_params=DatasetParams(\n",
    "    name = 'rico1',\n",
    "    data_path='../datasets/rico1.csv',\n",
    "    columns_identifier='ts_'\n",
    ")\n",
    "\n",
    "synth_dataset_params=DatasetParams(\n",
    "    name = 'synth',\n",
    "    data_path='../datasets/synth.csv',\n",
    "    columns_identifier='ts_'\n",
    ")\n",
    "\n",
    "real_dataset = RICODataset(real_dataset_params)\n",
    "synth_dataset = RICODataset(synth_dataset_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: rico1+synth \n",
      "Shape : torch.Size([358, 24, 1])\n"
     ]
    }
   ],
   "source": [
    "add_merged_dataset = real_dataset + synth_dataset\n",
    "print(add_merged_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or also : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: new_name \n",
      "Shape : torch.Size([358, 24, 1])\n"
     ]
    }
   ],
   "source": [
    "self_merged_dataset = real_dataset.merge(synth_dataset, name='new_name')\n",
    "print(self_merged_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tensor :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([358, 24, 1])\n"
     ]
    }
   ],
   "source": [
    "torch_data = add_merged_dataset.to(\"torch\")\n",
    "print(type(torch_data))\n",
    "print(torch_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(358, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "torch_data = add_merged_dataset.to(\"numpy\", _dtype=\"float32\")\n",
    "print(type(torch_data))\n",
    "print(torch_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pandas: (Only supported for univariate datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(358, 24)\n"
     ]
    }
   ],
   "source": [
    "pd_data = add_merged_dataset.to(\"pandas\", _dtype=\"float32\")\n",
    "print(type(pd_data))\n",
    "print(pd_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trstr mix & Balanced batch sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rico_data_module import trstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∞ real points in train: 51 \n",
      "N¬∞ synth points in train: 204\n",
      "N¬∞ points in test : 51\n"
     ]
    }
   ],
   "source": [
    "train, test = trstr(real=real_dataset, synth = synth_dataset, r = 0.8, ignore_warnings=False)\n",
    "\n",
    "synth_indices = train.ori_indices\n",
    "real_indices = train.extra_indices\n",
    "\n",
    "print(f\"N¬∞ real points in train: {len(real_indices)} \\nN¬∞ synth points in train: {len(synth_indices)}\")\n",
    "print(f\"N¬∞ points in test : {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è If there are not enough synthetic samples to support the specified r/s ratio, the highest possible ratio will be used instead (i.e all synthetic samples will be used). <br>\n",
    "Try increasing r until the warning shows up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mWarning:\u001b[0m split_ratio is greater than 1, Increase the size of the synth dataset to avoid this warning : 1.79\n",
      "\t\u001b[92mDefaulting to 1\u001b[0m\n",
      "\n",
      "Length of train: 307 || is equal to 51 = len(real)/2 + 256 = len(synth)\n",
      "Length of test: 51\n"
     ]
    }
   ],
   "source": [
    "train_outbounded, test_outbounded = trstr(real=real_dataset, synth = synth_dataset, r = 0.9, ignore_warnings=False)\n",
    "print()\n",
    "print(f\"Length of train: {len(train_outbounded)} || is equal to 51 = len(real)/2 + 256 = len(synth)\")\n",
    "print(f\"Length of test: {len(test_outbounded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced batch sampling\n",
    "Will create batches with uniformly distributed real samples, ensuring that no batch is only synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rico_data_module import BalancedBatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = BalancedBatchSampler(real_indices, synth_indices=synth_indices, batch_size=10)\n",
    "loader = DataLoader(train, batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows the distribution of synth samples (1.0 elements) accross the batches.\n",
    "Note how this should reflect the ratio specified earlier (0.8 in this case), except maybe for the last batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\n"
     ]
    }
   ],
   "source": [
    "print([np.count_nonzero(batch[:,0] == 1.0)/len(batch) for batch in loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're all set üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
